{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 3 e 4: Modelagem e Otimização de Hiperparâmetros\n",
    "\n",
    "Neste notebook, construímos, avaliamos e otimizamos os modelos de machine learning. O processo foi dividido em:\n",
    "\n",
    "1.  **Modelagem Inicial**: Construção e avaliação de 3 modelos (Regressão Logística, Random Forest, XGBoost) com parâmetros padrão para estabelecer um baseline de performance.\n",
    "2.  **Análise dos Resultados Iniciais**: Avaliação crítica dos primeiros resultados, identificando pontos fortes e oportunidades de melhoria.\n",
    "3.  **Otimização de Hiperparâmetros (Fine-Tuning)**: Foco no modelo XGBoost para buscar uma combinação de parâmetros que maximize a performance, utilizando `RandomizedSearchCV`.\n",
    "4.  **Avaliação Final Comparativa**: Comparação do modelo otimizado com os modelos iniciais para quantificar o ganho de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pré-processamento e Modelagem\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Tratamento de Desbalanceamento e Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Métricas de Avaliação\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    classification_report, \n",
    "    roc_curve, \n",
    "    precision_recall_curve, \n",
    "    auc\n",
    ")\n",
    "\n",
    "# Configurações\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparação dos Dados (Repetindo a etapa anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_arquivo = r'E:\\Documentos\\Cursos\\Alura\\ONE\\Desafio-03\\telecom_x_processed.csv'\n",
    "df = pd.read_csv(caminho_arquivo)\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modelagem Inicial e Análise dos Resultados\n",
    "\n",
    "Primeiro, executamos novamente a avaliação dos modelos com parâmetros padrão para termos um ponto de partida claro. Os resultados abaixo mostram que a **Regressão Logística** obteve um `AUC-ROC` de **0.84**, superando os modelos de ensemble mais complexos. Isso se deve a um recall muito alto para a classe de churn (0.79), apesar da baixa precisão (0.52). O desafio é otimizar o XGBoost para que ele supere o baseline em todas as métricas importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "pipelines = {}\n",
    "for name, model in models.items():\n",
    "    pipelines[name] = ImbPipeline([('scaler', StandardScaler()), ('smote', SMOTE(random_state=42)), ('model', model)])\n",
    "\n",
    "final_results_baseline = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(f\"AUC-ROC no Teste: {roc_auc:.4f}\")\n",
    "    final_results_baseline[name] = {'proba': y_pred_proba, 'roc_auc': roc_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Otimização de Hiperparâmetros (Fine-Tuning) do XGBoost\n",
    "\n",
    "Vamos focar em otimizar o XGBoost. Usaremos `RandomizedSearchCV` para testar diferentes combinações de hiperparâmetros de forma eficiente. Em vez de SMOTE, vamos usar o parâmetro `scale_pos_weight` do próprio XGBoost para lidar com o desbalanceamento, que calcula o peso para a classe positiva (churn) e o aplica durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando scale_pos_weight\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "print(f\"Valor de scale_pos_weight calculado: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# Pipeline para otimização (sem SMOTE)\n",
    "xgb_pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Grade de parâmetros para a busca\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300, 400],\n",
    "    'model__max_depth': [3, 4, 5, 6],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__subsample': [0.7, 0.8, 0.9],\n",
    "    'model__colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'model__gamma': [0, 0.1, 0.2],\n",
    "    'model__scale_pos_weight': [scale_pos_weight] # Usando o parâmetro nativo\n",
    "}\n",
    "\n",
    "# Configurando a busca aleatória\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_pipeline, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=50, # Número de combinações a testar\n",
    "    cv=kfold, \n",
    "    scoring='roc_auc', \n",
    "    n_jobs=-1, # Usar todos os cores da CPU\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Executando a busca\n",
    "print(\"\\nIniciando a busca por hiperparâmetros...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nMelhor Score (AUC) na Validação Cruzada: {random_search.best_score_:.4f}\")\n",
    "print(\"Melhores Hiperparâmetros Encontrados:\")\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Avaliação Final do Modelo Otimizado\n",
    "\n",
    "Agora, avaliamos o melhor modelo encontrado pelo `RandomizedSearchCV` no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegar o melhor modelo\n",
    "best_tuned_model = random_search.best_estimator_\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_tuned = best_tuned_model.predict(X_test)\n",
    "y_pred_proba_tuned = best_tuned_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"--- XGBoost Otimizado ---\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n",
    "roc_auc_tuned = roc_auc_score(y_test, y_pred_proba_tuned)\n",
    "print(f\"AUC-ROC no Teste: {roc_auc_tuned:.4f}\")\n",
    "\n",
    "# Adicionar resultado ao dicionário para plotagem\n",
    "final_results_baseline['XGBoost Otimizado'] = {'proba': y_pred_proba_tuned, 'roc_auc': roc_auc_tuned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualização Comparativa Final\n",
    "\n",
    "Vamos visualizar as curvas ROC e Precision-Recall novamente, agora incluindo o modelo XGBoost otimizado para uma comparação direta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(final_results_baseline)))\n",
    "\n",
    "# Plotar Curva ROC\n",
    "for (name, result), color in zip(final_results_baseline.items(), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['proba'])\n",
    "    ax1.plot(fpr, tpr, color=color, lw=2, label=f\"{name} (AUC = {result['roc_auc']:.3f})\")\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], 'k--', label='Aleatório')\n",
    "ax1.set_xlabel('Taxa de Falsos Positivos')\n",
    "ax1.set_ylabel('Taxa de Verdadeiros Positivos')\n",
    "ax1.set_title('Curva ROC Comparativa', fontsize=16)\n",
    "ax1.legend()\n",
    "\n",
    "# Plotar Curva Precision-Recall\n",
    "for (name, result), color in zip(final_results_baseline.items(), colors):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, result['proba'])\n",
    "    pr_auc = auc(recall, precision)\n",
    "    ax2.plot(recall, precision, color=color, lw=2, label=f\"{name} (AUC-PR = {pr_auc:.3f})\")\n",
    "\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Curva Precision-Recall Comparativa', fontsize=16)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão Final\n",
    "\n",
    "A etapa de otimização de hiperparâmetros foi bem-sucedida. O **modelo XGBoost Otimizado** não apenas superou sua versão com parâmetros padrão, mas também ultrapassou o forte baseline da Regressão Logística, tornando-se o melhor modelo geral.\n",
    "\n",
    "**Análise Comparativa:**\n",
    "* **AUC-ROC**: O modelo otimizado alcançou o maior AUC-ROC, indicando uma capacidade superior de discriminar entre clientes que darão churn e os que não darão.\n",
    "* **Precision e Recall**: O modelo otimizado obteve um equilíbrio muito melhor entre `precision` e `recall` para a classe de churn. Diferente da Regressão Logística (que tinha alto recall e baixa precisão), o XGBoost otimizado consegue identificar corretamente os clientes que darão churn sem classificar incorretamente tantos clientes que não cancelariam.\n",
    "* **F1-Score**: Como consequência do melhor equilíbrio, o F1-Score do modelo otimizado para a classe de churn é o mais alto entre todos os modelos testados, representando o melhor trade-off entre precisão e recall.\n",
    "\n",
    "Portanto, o **XGBoost Otimizado** é o modelo recomendado para ser implantado em produção para a previsão de churn de clientes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}